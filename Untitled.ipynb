{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy_arglex import arglex"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/anaconda3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: spacy.morphology.Morphology size changed, may indicate binary incompatibility. Expected 104 from C header, got 112 from PyObject\n",
      "  return f(*args, **kwds)\n",
      "/opt/anaconda3/lib/python3.7/importlib/_bootstrap.py:219: RuntimeWarning: spacy.vocab.Vocab size changed, may indicate binary incompatibility. Expected 96 from C header, got 104 from PyObject\n",
      "  return f(*args, **kwds)\n"
     ]
    }
   ],
   "source": [
    "import spacy\n",
    "from spacy.matcher import Matcher\n",
    "from spacy.tokens import Span, Token, Doc\n",
    "from spacy import displacy\n",
    "import neuralcoref"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy_arglex import arglex\n",
    "import spacy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "[E152] The attribute IN is not supported for token patterns. Please use the option validate=True with Matcher, PhraseMatcher, or EntityRuler for more details.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-2-c3a7d21e7a49>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marglex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspacy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/MSc Behavioural and Data Science/Political Sentiment Shift/Lexicons/spacy_arglex/spacy_arglex.py\u001b[0m in \u001b[0;36marglex\u001b[0;34m(object)\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_pipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDifficulty\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnlp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Difficulty'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     62\u001b[0m     \u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_pipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mDoubt\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnlp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Doubt'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 63\u001b[0;31m     \u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_pipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mEmphasis\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnlp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Emphasis'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     64\u001b[0m     \u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_pipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mGeneralization\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnlp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Generalization'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     65\u001b[0m     \u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_pipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mInconsistency\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnlp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Inconsistency'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/MSc Behavioural and Data Science/Political Sentiment Shift/Lexicons/spacy_arglex/emphasis/emphasis.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, nlp, object)\u001b[0m\n\u001b[1;32m    213\u001b[0m              \u001b[0;34m{\u001b[0m\u001b[0;34m'LEMMA'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'want'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    214\u001b[0m              \u001b[0;34m{\u001b[0m\u001b[0;34m'LOWER'\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0;34m'to'\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 215\u001b[0;31m              {'LOWER': {'IN':['highlight', 'emphasize', 'underscore']}}]\n\u001b[0m\u001b[1;32m    216\u001b[0m         )\n\u001b[1;32m    217\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32mmatcher.pyx\u001b[0m in \u001b[0;36mspacy.matcher.matcher.Matcher.add\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mmatcher.pyx\u001b[0m in \u001b[0;36mspacy.matcher.matcher._preprocess_pattern\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;32mmatcher.pyx\u001b[0m in \u001b[0;36mspacy.matcher.matcher._get_attr_values\u001b[0;34m()\u001b[0m\n",
      "\u001b[0;31mValueError\u001b[0m: [E152] The attribute IN is not supported for token patterns. Please use the option validate=True with Matcher, PhraseMatcher, or EntityRuler for more details."
     ]
    }
   ],
   "source": [
    "test = arglex(spacy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'LOWER': 'in'},\n",
       " {'LOWER': 'order'},\n",
       " {'LOWER': 'to'},\n",
       " {'IS_ALPHA': True, 'OP': '+'},\n",
       " {'LEMMA': {'IN': ['need', 'must', 'have']}},\n",
       " {'LOWER': 'to'}]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "        self.matcher.add(\"Emphasis\", None,\n",
    "                    \n",
    "            #clearly\n",
    "            [{'LOWER':'clearly'}],\n",
    "                         \n",
    "            #obviously\n",
    "            [{'LOWER':'obviously'}],\n",
    "            \n",
    "            #patently\n",
    "            [{'LOWER':'patently'}],\n",
    "            \n",
    "            #when you (really )?think about it\n",
    "            [{'LOWER':'when'},\n",
    "             {'LOWER': 'you'},\n",
    "             {'LOWER': 'really', 'OP':'?'},\n",
    "             {'LOWER': 'think'},\n",
    "             {'LOWER': 'about'},\n",
    "             {'LOWER': 'it'}],\n",
    "            \n",
    "            #(it is|it\\'s) ((really|pretty) )?(obvious|evident|clear) (that)?\n",
    "            [{'LOWER':'it'},\n",
    "             {'LEMMA': 'be'},\n",
    "             {'LOWER': {'IN':['really', 'pretty']}, 'OP':'?'},\n",
    "             {'LOWER': {'IN':['obvious', 'evident', 'clear']}},\n",
    "             {'LOWER': 'that', 'OP':'?'}],\n",
    "            \n",
    "            #definitely\n",
    "             [{'LOWER':'definitely'}],\n",
    "            \n",
    "            #i have to say\n",
    "            [{'POS':'PRON'},\n",
    "             {'LEMMA': 'have'},\n",
    "             {'LOWER': 'to'},\n",
    "             {'LOWER': 'say'}],\n",
    "                         \n",
    "            #i\\'ve got to say\n",
    "            [{'POS':'PRON'},\n",
    "             {'LEMMA': 'have'},\n",
    "             {'LOWER': 'got'},\n",
    "             {'LOWER': 'to'},\n",
    "             {'LOWER': 'say'}],\n",
    "                         \n",
    "            #i\\'ve gotta say\n",
    "            [{'POS':'PRON'},\n",
    "             {'LEMMA': 'have'},\n",
    "             {'LOWER': 'gotta'},\n",
    "             {'LOWER': 'say'}],\n",
    "                         \n",
    "            #i should say\n",
    "            [{'POS':'PRON'},\n",
    "             {'LOWER': 'should'},\n",
    "             {'LOWER': 'say'}],\n",
    "                         \n",
    "            #surely\n",
    "            [{'LOWER':'surely'}],\n",
    "            \n",
    "            #for sure\n",
    "            [{'LOWER':'for'},\n",
    "             {'LOWER': 'sure'}],       \n",
    "                         \n",
    "            #(@BE) ((sure)|(certain)|(confident)) (that)?\n",
    "            [{'LEMMA':'be'},\n",
    "             {'LOWER': 'sure'}],   \n",
    "                         \n",
    "            #of course\n",
    "            [{'LOWER':'of'},\n",
    "             {'LOWER': 'course'}],\n",
    "                         \n",
    "            #no doubt about it\n",
    "            [{'LOWER':'no'},\n",
    "             {'LOWER': 'doubt'},\n",
    "             {'LOWER': 'about'},\n",
    "             {'LOWER': 'it'}],\n",
    "            \n",
    "            #doubtless\n",
    "            [{'LOWER':'doubtless'}],\n",
    "                         \n",
    "            #without a doubt\n",
    "            [{'LOWER':'without'},\n",
    "             {'LOWER': 'a'},\n",
    "             {'LOWER': 'doubt'}],\n",
    "                         \n",
    "                         \n",
    "            #I have no doubt (that)?\n",
    "            [{'POS':'PRON'},\n",
    "             {'LEMMA': 'have'},\n",
    "             {'LOWER' : 'no'},\n",
    "             {'LOWER': 'doubt'},\n",
    "             {'LOWER': 'that', 'OP':'?'}],\n",
    "            \n",
    "            #I bet (that)?\n",
    "            [{'POS':'PRON'},\n",
    "             {'LEMMA': 'bet'},\n",
    "             {'LOWER': 'that', 'OP':'?'}],\n",
    "                         \n",
    "            #(@BE) bound to\n",
    "            [{'LEMMA':'be'},\n",
    "             {'LOWER': 'bound'},\n",
    "             {'LOWER': 'to'}],\n",
    "                         \n",
    "            #no two ways about it\n",
    "            [{'LOWER':'no'},\n",
    "             {'LOWER': 'two'},\n",
    "             {'LOWER': 'ways'},\n",
    "             {'LOWER': 'about'},\n",
    "             {'LOWER': 'it'}],\n",
    "                         \n",
    "            #there ((is)|(are)) no two ways about it\n",
    "            [{'LOWER':'there'},\n",
    "             {'LEMMA': 'be'},\n",
    "             {'LOWER':'no'},\n",
    "             {'LOWER': 'two'},\n",
    "             {'LOWER': 'ways'},\n",
    "             {'LOWER': 'about'},\n",
    "             {'LOWER': 'it'}], \n",
    "                         \n",
    "            #((the)|(one)) ((thing)|(issue)|(question)|(problem)) (@MODAL )?(@BE) (that)?\n",
    "            [{'LOWER':{'IN':['one', 'the']}},\n",
    "             {'LOWER': {'IN': ['thing', 'issue', 'question', 'problem']}},\n",
    "             {'_':{'MODAL':True}, 'OP':'?'},\n",
    "             {'LEMMA': 'be'},\n",
    "             {'LOWER': 'that', 'OP': '?'}], \n",
    "                         \n",
    "            #my feeling is (that)?\n",
    "            [{'DEP': 'poss'},\n",
    "             {'LOWER': 'feeling'},\n",
    "             {'LEMMA': 'be'},\n",
    "             {'LOWER': 'that', 'OP': '?'}], \n",
    "                         \n",
    "            #that\\'s why\n",
    "            [{'LOWER':'that'},\n",
    "             {'LOWER': 'is'},\n",
    "             {'LOWER': 'why'}],\n",
    "                         \n",
    "            #that is why\n",
    "                         \n",
    "            #the idea (here )?is (that)?\n",
    "            [{'LOWER':'the'},\n",
    "             {'LOWER': 'idea'},\n",
    "             {'LOWER': 'here'},\n",
    "             {'LEMMA': 'be'},\n",
    "             {'LOWER': 'that', 'OP':'?'}],\n",
    "                         \n",
    "            #((my)|(the)) whole ((point)|(question)) is \n",
    "            [{'IN':[{'DEP':'poss'}, {'LOWER': 'the'}]},\n",
    "             {'LOWER': 'whole'},\n",
    "             {'LOWER': {'IN':['point', 'question']}},\n",
    "             {'LEMMA': 'be'}],    \n",
    "            \n",
    "            #what you have to do is \n",
    "            [{'LOWER':'what'},\n",
    "             {'POS': 'PRON'},\n",
    "             {'LEMMA': 'have'},\n",
    "             {'LOWER': 'to'},\n",
    "             {'LOWER': 'do'},\n",
    "             {'LEMMA': 'be'}],\n",
    "                         \n",
    "            #the reason is (that)?  \n",
    "            [{'LOWER':'the'},\n",
    "             {'LOWER': 'reason'},\n",
    "             {'LEMMA': 'be'},\n",
    "             {'LOWER': 'that', 'OP': '?'}],\n",
    "                         \n",
    "            #here\\'s what\n",
    "            [{'LOWER':'here'},\n",
    "             {'LOWER': 'is'},\n",
    "             {'LEMMA': 'what'}],\n",
    "                         \n",
    "            #here is what\n",
    "                         \n",
    "            #exactly\n",
    "            [{'LOWER':'exactly'}],\n",
    "                         \n",
    "            #precisely\n",
    "            [{'LOWER':'precisely'}],\n",
    "                         \n",
    "            #(@GONNA)\n",
    "                         \n",
    "            #(@GONNANEG)\n",
    "                         \n",
    "            #(@GONNANEGCL)\n",
    "                         \n",
    "            #(@GONNACL)\n",
    "                         \n",
    "            #what will happen is\n",
    "            [{'LOWER':'what'},\n",
    "             {'LOWER': 'will'},\n",
    "             {'LOWER': 'happen'},\n",
    "             {'LOWER': 'is'}],\n",
    "                         \n",
    "            #what\\'ll happen is\n",
    "                         \n",
    "            #what\\'s ((gonna)|(going to)) happen is\n",
    "            [{'LOWER':'what'},\n",
    "             {'LOWER': 'is'},\n",
    "             {'LOWER': {'IN':['gonna', 'going']}},\n",
    "             {'LOWER': 'to', 'OP': '?'},\n",
    "             {'LOWER': 'happen'},\n",
    "             {'LOWER': 'is'}],\n",
    "                                         \n",
    "            #what is ((gonna)|(going to)) happen is\n",
    "                         \n",
    "            #i want to (highlight|emphasize|underscore)\n",
    "            [{'POS':'PRON'},\n",
    "             {'LEMMA': 'want'},\n",
    "             {'LOWER': 'to'},\n",
    "             {'LOWER': {'IN':['highlight', 'emphasize', 'underscore']}}]\n",
    "        )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Assessment(object):\n",
    "    \n",
    "    def __init__(self, object):\n",
    "        \n",
    "        Span.set_extension(\"assessment\", default = None, force = True)\n",
    "        self.matcher = Matcher(object.vocab)\n",
    "        self.matcher.add(\"Assessment\", None,\n",
    "            \n",
    "            #(our|my) (opinion|understanding) (is|was) that\n",
    "            [{'DEP':'poss'},\n",
    "            {\"LOWER\": {'IN':['understanding', 'opinion']}}, \n",
    "            {'LEMMA': 'be'},\n",
    "            {'LOWER': 'that'}],\n",
    "\n",
    "            # it (is|was) (our|my) (opinion|understanding) (that)?                     \n",
    "            [{'LOWER':'it'},\n",
    "            {'LEMMA': 'be'},\n",
    "            {'DEP': 'poss'},\n",
    "            {'LOWER' :{'IN':['opinion', 'understanding']}},\n",
    "            {'LOWER': 'that', 'OP':'?'}],\n",
    "\n",
    "            #in (our|my) opinion\n",
    "            [{'LOWER': 'in'},\n",
    "             {'DEP': 'poss'},\n",
    "             {'LEMMA': 'opinion'}],\n",
    "\n",
    "            #(our|my) take on\n",
    "            [{'DEP': 'poss'},\n",
    "             {'LOWER': 'take'},\n",
    "             {'LOWER': 'on'}],\n",
    "\n",
    "            #it (seems|seemed) to (us|me) (that)?\n",
    "            [{'LOWER': 'it'},\n",
    "             {'LEMMA': 'seem'},\n",
    "             {'LOWER': 'to'},\n",
    "             {'POS': 'PRON'},\n",
    "             {'LOWER': 'that', 'OP':'?'}],\n",
    "\n",
    "            #it (seems|seemed) (that)?\n",
    "            [{'LOWER': 'it'},\n",
    "             {'LEMMA': 'seem'},\n",
    "             {'LOWER': 'that', 'OP':'?'}],\n",
    "\n",
    "            #it would seem to (us|me)?\n",
    "            [{'LOWER': 'it'},\n",
    "             {'LOWER': 'would'},\n",
    "             {'LOWER': 'seem'},\n",
    "             {'LOWER': 'to'},\n",
    "             {'POS': 'PRON', 'OP':'?'}],\n",
    "\n",
    "            #it would appear to (us|me)?\n",
    "            [{'LOWER': 'it'},\n",
    "             {'LOWER': 'would'},\n",
    "             {'LOWER': 'appear'},\n",
    "             {'LOWER': 'to'},\n",
    "             {'POS': 'PRON', 'OP':'?'}],\n",
    "\n",
    "            #it appear to (us|me)?\n",
    "            [{'LOWER': 'it'},\n",
    "             {'LEMMA': 'appear'},\n",
    "             {'LOWER': 'to'},\n",
    "             {'POS': 'PRON', 'OP':'?'}],\n",
    "\n",
    "            #(the|my|our) ([\\w]+[ ])?point is (that)?\n",
    "            [{'DEP': {'IN':['poss', 'det']}},\n",
    "             {'IS_ALPHA': True, 'OP':'?'},\n",
    "             {'LOWER': 'point'},\n",
    "             {'LEMMA': 'be'},\n",
    "             {'LOWER': 'that', 'OP':'?'}]\n",
    "\n",
    "        )\n",
    "    \n",
    "    def __call__(self, doc):\n",
    "        matches = self.matcher(doc)\n",
    "        for match_id, start, end in matches:\n",
    "            sents = Span(doc, start, end).sent\n",
    "            sent_start, sent_end = sents.start, sents.end\n",
    "            opinion = Span(doc, sent_start, sent_end, label = \"ASS\")\n",
    "            doc._.opinion.append(opinion,)\n",
    "        return doc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class spacy_arglex(object):\n",
    "    \n",
    "    def __init__(self, object):\n",
    "        self.nlp = object.load(\"en_core_web_sm\")\n",
    "        \n",
    "        # Set Document Extensions\n",
    "        object.tokens.Doc.set_extension(\"opinion\", default = [], force = True)\n",
    "        \n",
    "        # Set Span extensions\n",
    "        object.tokens.Span.set_extension(\"assessment\", default = None, force = True) \n",
    "        \n",
    "        # Set Token Extensions\n",
    "        object.tokens.Token.set_extension(\"is_emo\", getter = lambda token: token.lemma_ \\\n",
    "                            in ('like', 'adore', 'want', 'prefer', 'love', 'enjoy',\n",
    "                               'adoration', 'want', 'preference', 'love', 'enjoyment',\n",
    "                               'hate', 'dislike', 'disprefer', 'dispreference'), force = True)\n",
    "        \n",
    "        opinion_tag = Assessment(self.nlp)\n",
    "        self.nlp.add_pipe(opinion_tag, last = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp(\"this apple is a \")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'PhraseMatcher' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-3-c3a7d21e7a49>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mtest\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0marglex\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mspacy\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m~/Desktop/MSc Behavioural and Data Science/Political Sentiment Shift/Lexicons/spacy_arglex/spacy_arglex.py\u001b[0m in \u001b[0;36marglex\u001b[0;34m(object)\u001b[0m\n\u001b[1;32m     57\u001b[0m     \u001b[0;31m# Add to pipeline\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     58\u001b[0m     \u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_pipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAssessment\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnlp\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Assessment'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 59\u001b[0;31m     \u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_pipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mAuthority\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnlp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Authority'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     60\u001b[0m     \u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_pipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCausation\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnlp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Causation'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     61\u001b[0m     \u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0madd_pipe\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mConditionals\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mnlp\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mname\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'Conditionals'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlast\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m~/Desktop/MSc Behavioural and Data Science/Political Sentiment Shift/Lexicons/spacy_arglex/authority/authority.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, object)\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobject\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmatcher\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mPhraseMatcher\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobject\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvocab\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mattr\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"LOWER\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m         \u001b[0mterms\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0;34m\"according to\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mpatterns\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mnlp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmake_doc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtext\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mtext\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mterms\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'PhraseMatcher' is not defined"
     ]
    }
   ],
   "source": [
    "test = arglex(spacy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "a = test.nlp(\"It was my understanding that burgers are life. However, I do not like seafood. It would seem to me that this is tasty\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ASS'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a._.opinion[0].label_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "from spacy.tokens import Doc\n",
    "Doc.set_extension(\"opinion\", default = False, force = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_event_ent(matcher, doc, i, matches):\n",
    "    match_id, start, end = matches[i]\n",
    "    opinion = Span(doc, start, end, label=\"Assessment\")\n",
    "    doc.opinion += (opinion,)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 280,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ASS'"
      ]
     },
     "execution_count": 280,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a._.opinion[0].label_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 208,
   "metadata": {},
   "outputs": [],
   "source": [
    "matcher = Matcher(nlp.vocab)\n",
    "matcher.add(\"assessment\", None ,\n",
    "            [{'DEP':'poss'},\n",
    "            {\"LOWER\": {'IN':['understanding', 'opinion']}}, \n",
    "            {'LEMMA': 'be'},\n",
    "            {'LOWER': 'that'}],\n",
    "\n",
    "            # it (is|was) (our|my) (opinion|understanding) (that)?                     \n",
    "            [{'LOWER':'it'},\n",
    "            {'LEMMA': 'be'},\n",
    "            {'DEP': 'poss'},\n",
    "            {'LOWER' :{'IN':['opinion', 'understanding']}},\n",
    "            {'LOWER': 'that', 'OP':'?'}],\n",
    "\n",
    "            #in (our|my) opinion\n",
    "            [{'LOWER': 'in'},\n",
    "             {'DEP': 'poss'},\n",
    "             {'LEMMA': 'opinion'}],\n",
    "\n",
    "            #(our|my) take on\n",
    "            [{'DEP': 'poss'},\n",
    "             {'LOWER': 'take'},\n",
    "             {'LOWER': 'on'}],\n",
    "\n",
    "            #it (seems|seemed) to (us|me) (that)?\n",
    "            [{'LOWER': 'it'},\n",
    "             {'LEMMA': 'seem'},\n",
    "             {'LOWER': 'to'},\n",
    "             {'POS': 'PRON'},\n",
    "             {'LOWER': 'that', 'OP':'?'}],\n",
    "\n",
    "            #it (seems|seemed) (that)?\n",
    "            [{'LOWER': 'it'},\n",
    "             {'LEMMA': 'seem'},\n",
    "             {'LOWER': 'that', 'OP':'?'}],\n",
    "\n",
    "            #it would seem to (us|me)?\n",
    "            [{'LOWER': 'it'},\n",
    "             {'LOWER': 'would'},\n",
    "             {'LOWER': 'seem'},\n",
    "             {'LOWER': 'to'},\n",
    "             {'POS': 'PRON', 'OP':'?'}],\n",
    "\n",
    "            #it would appear to (us|me)?\n",
    "            [{'LOWER': 'it'},\n",
    "             {'LOWER': 'would'},\n",
    "             {'LOWER': 'appear'},\n",
    "             {'LOWER': 'to'},\n",
    "             {'POS': 'PRON', 'OP':'?'}],\n",
    "\n",
    "            #it appear to (us|me)?\n",
    "            [{'LOWER': 'it'},\n",
    "             {'LEMMA': 'appear'},\n",
    "             {'LOWER': 'to'},\n",
    "             {'POS': 'PRON', 'OP':'?'}],\n",
    "\n",
    "            #(the|my|our) ([\\w]+[ ])?point is (that)?\n",
    "            [{'DEP': {'IN':['poss', 'det']}},\n",
    "             {'IS_ALPHA': True, 'OP':'?'},\n",
    "             {'LOWER': 'point'},\n",
    "             {'LEMMA': 'be'},\n",
    "             {'LOWER': 'that', 'OP':'?'}])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 209,
   "metadata": {},
   "outputs": [],
   "source": [
    "matches = matcher(doc)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 270,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "9"
      ]
     },
     "execution_count": 270,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a[4].sent.end"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 226,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(16732015447806033820, 0), (16732015447806033820, 17)]"
      ]
     },
     "execution_count": 226,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(set([i[0:2] for i in matches]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 227,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[(16732015447806033820, 0),\n",
       " (16732015447806033820, 0),\n",
       " (16732015447806033820, 17),\n",
       " (16732015447806033820, 17)]"
      ]
     },
     "execution_count": 227,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "[i[0:2] for i in matches]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "max(matches, key=lambda x: x[2])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "def arglex(object):\n",
    "    nlp = object.load('en_core_web_sm')\n",
    "    \n",
    "    # Set Document Extensions\n",
    "    object.tokens.Doc.set_extension(\"opinion\", default = [], force = True)\n",
    "    object.tokens.Span.set_extension(\"assessment\", default = None, force = True) \n",
    "    \n",
    "    ass = Assessment(nlp)\n",
    "    nlp.add_pipe(ass, name = 'Assessment', last = True)\n",
    "    return nlp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = arglex(spacy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "nlp = spacy.load('en_core_web_sm')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "doc = nlp('my understanding was that this is cool.')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'ASS'"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "doc._.opinion[0].label_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "spacy.tokens.Token.set_extension(\"is_spoken\", getter = lambda token: token.text.lower() in ('uh','um', 'mm-hmm', 'uh-huh', 'huh'), force = True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
